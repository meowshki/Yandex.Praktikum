{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»\n",
    "\n",
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "import torch\n",
    "import transformers\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import lightgbm as lgbm\n",
    "import catboost as catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159566</td>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159567</td>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159568</td>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159569</td>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159570</td>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "0       Explanation\\nWhy the edits made under my usern...      0\n",
       "1       D'aww! He matches this background colour I'm s...      0\n",
       "2       Hey man, I'm really not trying to edit war. It...      0\n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4       You, sir, are my hero. Any chance you remember...      0\n",
       "...                                                   ...    ...\n",
       "159566  \":::::And for the second time of asking, when ...      0\n",
       "159567  You should be ashamed of yourself \\n\\nThat is ...      0\n",
       "159568  Spitzer \\n\\nUmm, theres no actual article for ...      0\n",
       "159569  And it looks like it was actually you who put ...      0\n",
       "159570  \"\\nAnd ... I really don't think you understand...      0\n",
       "\n",
       "[159571 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В таблице есть две столбца: text, собственно текст комментария, и toxic, который содержит целевой признак по сентименту фразы. Поработаем с датасетом,произведём стандратные шаги на выявление ошибок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      "text     159571 non-null object\n",
      "toxic    159571 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "toxic    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143346\n",
       "1     16225\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пропусков, дубликатов - не обнаружено, поэтому выделяем корпус данных для обучения модели из обучающей выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = list(df['text'])\n",
    "corpus[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заведем функцию для очистки текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прогоняем через эту функцию циклом весь наш текст."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanation Why the edits made under my username Hardcore Metallica Fan were reverted  They weren t vandalisms  just closure on some GAs after I voted at New York Dolls FAC  And please don t remove the template from the talk page since I m retired now             \n"
     ]
    }
   ],
   "source": [
    "for i in range(len(corpus)):\n",
    "    corpus[i] = clear_text(corpus[i])\n",
    "    \n",
    "print(corpus[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбиваем фразу на слагаемые, то есть, слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Explanation', 'Why', 'the', 'edits', 'made', 'under', 'my', 'username', 'Hardcore', 'Metallica', 'Fan', 'were', 'reverted', 'They', 'weren', 't', 'vandalisms', 'just', 'closure', 'on', 'some', 'GAs', 'after', 'I', 'voted', 'at', 'New', 'York', 'Dolls', 'FAC', 'And', 'please', 'don', 't', 'remove', 'the', 'template', 'from', 'the', 'talk', 'page', 'since', 'I', 'm', 'retired', 'now']\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(corpus)):\n",
    "    corpus[i] = nltk.word_tokenize(corpus[i])\n",
    "    \n",
    "print(corpus[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заводим функцию лемматизации слова в тело кода."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemm_list = lemmatizer.lemmatize(text)\n",
    "    return lemm_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вновь прогон]ем весь текст через функцию леммы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Explanation', 'Why', 'the', 'edits', 'made', 'under', 'my', 'username', 'Hardcore', 'Metallica', 'Fan', 'were', 'reverted', 'They', 'weren', 't', 'vandalism', 'just', 'closure', 'on', 'some', 'GAs', 'after', 'I', 'voted', 'at', 'New', 'York', 'Dolls', 'FAC', 'And', 'please', 'don', 't', 'remove', 'the', 'template', 'from', 'the', 'talk', 'page', 'since', 'I', 'm', 'retired', 'now']\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(corpus)):\n",
    "    for n in range(len(corpus[i])):\n",
    "        corpus[i][n] = lemmatize(corpus[i][n])        \n",
    "\n",
    "print(corpus[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь джойним обратно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanation Why the edits made under my username Hardcore Metallica Fan were reverted They weren t vandalism just closure on some GAs after I voted at New York Dolls FAC And please don t remove the template from the talk page since I m retired now\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(corpus)):\n",
    "    corpus[i] = \" \".join(corpus[i])\n",
    "    \n",
    "print(corpus[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вводим стоп-слова, создаем счетчик, уоторый превратит текст в мешок слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords') \n",
    "stop_words = set(stopwords.words('english')) \n",
    "count_vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Передаем корпуск текстов через фит."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = count_vect.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер мешка без учёта стоп-слов: (159571, 164412)\n"
     ]
    }
   ],
   "source": [
    "print(\"Размер мешка без учёта стоп-слов:\", bow.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь передадим счетчику корпус текстов с учетом стоп-слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(stop_words=stop_words)\n",
    "bow = count_vect.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считаем TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tf_idf = TfidfVectorizer(stop_words=stop_words) \n",
    "tf_idf = count_tf_idf.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер матрицы: (159571, 164267)\n"
     ]
    }
   ],
   "source": [
    "print(\"Размер матрицы:\", tf_idf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим данные на обучающую, тестовую и валидационную."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, features_test, target, target_test = train_test_split(tf_idf, \n",
    "                                    df.toxic, test_size = 0.2, train_size = 0.8)\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(features, \n",
    "                                    target, test_size = 0.25, train_size = 0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные готовы, поехали их обучать и смотреть показатели метрики F1, главной для нас метрики в этом исследовании."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = make_scorer(f1_score , average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 5, 'class_weight': 'balanced'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parametrs_lr = { 'C': range (1, 10, 1),\n",
    "              'class_weight': ['balanced'],\n",
    "              }\n",
    "\n",
    "grid = GridSearchCV(model, parametrs_lr, scoring = 'f1', cv=5)\n",
    "grid.fit(features_train, target_train)\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=8, class_weight='balanced', dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=12345, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=12345, C=8, class_weight='balanced')\n",
    "model.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression F1_score 0.7537541915731155\n",
      "Logistic Regression accuracy_score 0.9470781764060786\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(features_test)\n",
    "print('Logistic Regression F1_score', f1_score(target_test, pred))\n",
    "print('Logistic Regression accuracy_score', accuracy_score(target_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score 0.7537541915731155\n"
     ]
    }
   ],
   "source": [
    "print('F1_score', f1_score(target_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.9, 'n_estimators': 1}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb = lgbm.LGBMClassifier()\n",
    "\n",
    "params_lgb = {'n_estimators': range (1, 10, 2),\n",
    "              'learning_rate': [0.1, 0.9],\n",
    "             }\n",
    " \n",
    "grid_lgb = GridSearchCV(lgb, params_lgb, scoring = 'f1', cv=5)\n",
    "\n",
    "grid_lgb.fit(features_train, target_train)\n",
    "\n",
    "grid_lgb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "               importance_type='split', learning_rate=0.9, max_depth=-1,\n",
       "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "               n_estimators=1, n_jobs=-1, num_leaves=31, objective=None,\n",
       "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb = lgbm.LGBMClassifier(n_estimators = 1, learning_rate = 0.9)\n",
    "\n",
    "lgb.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGB F1_score 0.6868863955119213\n",
      "LGB accuracy_score 0.9440388532038226\n"
     ]
    }
   ],
   "source": [
    "predictions_lgb = lgb.predict(features_test)\n",
    "print('LGB F1_score', f1_score(target_test, predictions_lgb))\n",
    "print('LGB accuracy_score', accuracy_score(target_test, predictions_lgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5917785\ttotal: 3.79s\tremaining: 0us\n",
      "0:\tlearn: 0.5944247\ttotal: 3.74s\tremaining: 0us\n",
      "0:\tlearn: 0.5947999\ttotal: 3.82s\tremaining: 0us\n",
      "0:\tlearn: 0.5937068\ttotal: 3.89s\tremaining: 0us\n",
      "0:\tlearn: 0.5938254\ttotal: 4.04s\tremaining: 0us\n",
      "0:\tlearn: 0.5917785\ttotal: 3.93s\tremaining: 19.7s\n",
      "1:\tlearn: 0.5159328\ttotal: 7.13s\tremaining: 14.3s\n",
      "2:\tlearn: 0.4566199\ttotal: 10.3s\tremaining: 10.3s\n",
      "3:\tlearn: 0.4086647\ttotal: 13.6s\tremaining: 6.82s\n",
      "4:\tlearn: 0.3722430\ttotal: 16.9s\tremaining: 3.39s\n",
      "5:\tlearn: 0.3452738\ttotal: 20.2s\tremaining: 0us\n",
      "0:\tlearn: 0.5944247\ttotal: 3.96s\tremaining: 19.8s\n",
      "1:\tlearn: 0.5177326\ttotal: 7.34s\tremaining: 14.7s\n",
      "2:\tlearn: 0.4571144\ttotal: 10.6s\tremaining: 10.6s\n",
      "3:\tlearn: 0.4096678\ttotal: 13.7s\tremaining: 6.87s\n",
      "4:\tlearn: 0.3720982\ttotal: 16.9s\tremaining: 3.39s\n",
      "5:\tlearn: 0.3438517\ttotal: 20s\tremaining: 0us\n",
      "0:\tlearn: 0.5947999\ttotal: 3.82s\tremaining: 19.1s\n",
      "1:\tlearn: 0.5175437\ttotal: 7.02s\tremaining: 14s\n",
      "2:\tlearn: 0.4556282\ttotal: 10.3s\tremaining: 10.3s\n",
      "3:\tlearn: 0.4096329\ttotal: 13.5s\tremaining: 6.76s\n",
      "4:\tlearn: 0.3722249\ttotal: 16.8s\tremaining: 3.36s\n",
      "5:\tlearn: 0.3425392\ttotal: 20s\tremaining: 0us\n",
      "0:\tlearn: 0.5937068\ttotal: 3.94s\tremaining: 19.7s\n",
      "1:\tlearn: 0.5162467\ttotal: 7.24s\tremaining: 14.5s\n",
      "2:\tlearn: 0.4567264\ttotal: 10.5s\tremaining: 10.5s\n",
      "3:\tlearn: 0.4095221\ttotal: 13.7s\tremaining: 6.87s\n",
      "4:\tlearn: 0.3737704\ttotal: 17s\tremaining: 3.41s\n",
      "5:\tlearn: 0.3444818\ttotal: 20.3s\tremaining: 0us\n",
      "0:\tlearn: 0.5938254\ttotal: 3.98s\tremaining: 19.9s\n",
      "1:\tlearn: 0.5172260\ttotal: 7.37s\tremaining: 14.7s\n",
      "2:\tlearn: 0.4556734\ttotal: 10.7s\tremaining: 10.7s\n",
      "3:\tlearn: 0.4101359\ttotal: 14s\tremaining: 6.99s\n",
      "4:\tlearn: 0.3744223\ttotal: 17.4s\tremaining: 3.47s\n",
      "5:\tlearn: 0.3458360\ttotal: 20.8s\tremaining: 0us\n",
      "0:\tlearn: 0.2633509\ttotal: 3.95s\tremaining: 0us\n",
      "0:\tlearn: 0.2709405\ttotal: 4.06s\tremaining: 0us\n",
      "0:\tlearn: 0.2723228\ttotal: 3.92s\tremaining: 0us\n",
      "0:\tlearn: 0.2687488\ttotal: 3.96s\tremaining: 0us\n",
      "0:\tlearn: 0.2686872\ttotal: 4s\tremaining: 0us\n",
      "0:\tlearn: 0.2633509\ttotal: 3.98s\tremaining: 19.9s\n",
      "1:\tlearn: 0.2310420\ttotal: 7.29s\tremaining: 14.6s\n",
      "2:\tlearn: 0.2146798\ttotal: 10.5s\tremaining: 10.5s\n",
      "3:\tlearn: 0.2006256\ttotal: 13.9s\tremaining: 6.94s\n",
      "4:\tlearn: 0.1934714\ttotal: 17.2s\tremaining: 3.44s\n",
      "5:\tlearn: 0.1873521\ttotal: 20.5s\tremaining: 0us\n",
      "0:\tlearn: 0.2709405\ttotal: 3.94s\tremaining: 19.7s\n",
      "1:\tlearn: 0.2347692\ttotal: 7.33s\tremaining: 14.7s\n",
      "2:\tlearn: 0.2154770\ttotal: 10.5s\tremaining: 10.5s\n",
      "3:\tlearn: 0.2041840\ttotal: 13.8s\tremaining: 6.92s\n",
      "4:\tlearn: 0.1950514\ttotal: 17.1s\tremaining: 3.42s\n",
      "5:\tlearn: 0.1888493\ttotal: 20.3s\tremaining: 0us\n",
      "0:\tlearn: 0.2723228\ttotal: 4.07s\tremaining: 20.4s\n",
      "1:\tlearn: 0.2362210\ttotal: 7.27s\tremaining: 14.5s\n",
      "2:\tlearn: 0.2184582\ttotal: 10.5s\tremaining: 10.5s\n",
      "3:\tlearn: 0.2041558\ttotal: 13.8s\tremaining: 6.89s\n",
      "4:\tlearn: 0.1961268\ttotal: 17s\tremaining: 3.39s\n",
      "5:\tlearn: 0.1900331\ttotal: 20.3s\tremaining: 0us\n",
      "0:\tlearn: 0.2687488\ttotal: 4.17s\tremaining: 20.8s\n",
      "1:\tlearn: 0.2316174\ttotal: 7.67s\tremaining: 15.3s\n",
      "2:\tlearn: 0.2136290\ttotal: 11.4s\tremaining: 11.4s\n",
      "3:\tlearn: 0.2031720\ttotal: 14.8s\tremaining: 7.38s\n",
      "4:\tlearn: 0.1949078\ttotal: 18s\tremaining: 3.59s\n",
      "5:\tlearn: 0.1871632\ttotal: 21.5s\tremaining: 0us\n",
      "0:\tlearn: 0.2686872\ttotal: 3.98s\tremaining: 19.9s\n",
      "1:\tlearn: 0.2322440\ttotal: 7.28s\tremaining: 14.6s\n",
      "2:\tlearn: 0.2147195\ttotal: 10.5s\tremaining: 10.5s\n",
      "3:\tlearn: 0.2018067\ttotal: 13.8s\tremaining: 6.89s\n",
      "4:\tlearn: 0.1950463\ttotal: 17s\tremaining: 3.4s\n",
      "5:\tlearn: 0.1885040\ttotal: 20.2s\tremaining: 0us\n",
      "0:\tlearn: 0.2603912\ttotal: 4.68s\tremaining: 23.4s\n",
      "1:\tlearn: 0.2325912\ttotal: 8.58s\tremaining: 17.2s\n",
      "2:\tlearn: 0.2161930\ttotal: 12.4s\tremaining: 12.4s\n",
      "3:\tlearn: 0.2053360\ttotal: 16.2s\tremaining: 8.08s\n",
      "4:\tlearn: 0.1925677\ttotal: 20.2s\tremaining: 4.03s\n",
      "5:\tlearn: 0.1880770\ttotal: 24s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.9, 'n_estimators': 6}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctb = catboost.CatBoostClassifier()\n",
    "\n",
    "params_ctb = {'n_estimators': range (1, 10, 5),\n",
    "              'learning_rate': [0.1, 0.9],\n",
    "             }\n",
    " \n",
    "grid_ctb = GridSearchCV(ctb, params_ctb, scoring = 'f1', cv=5)\n",
    "\n",
    "grid_ctb.fit(features_train, target_train)\n",
    "\n",
    "grid_ctb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.2603912\ttotal: 4.64s\tremaining: 23.2s\n",
      "1:\tlearn: 0.2325912\ttotal: 8.34s\tremaining: 16.7s\n",
      "2:\tlearn: 0.2161930\ttotal: 12.2s\tremaining: 12.2s\n",
      "3:\tlearn: 0.2053360\ttotal: 16.2s\tremaining: 8.11s\n",
      "4:\tlearn: 0.1925677\ttotal: 20.3s\tremaining: 4.07s\n",
      "5:\tlearn: 0.1880770\ttotal: 24.2s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f2d6768b2d0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctb = catboost.CatBoostClassifier(n_estimators = 6, learning_rate = 0.9)\n",
    "\n",
    "ctb.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost F1_score 0.6475856697819314\n",
      "CatBoost accuracy_score 0.943286855710481\n"
     ]
    }
   ],
   "source": [
    "predictions_ctb = ctb.predict(features_test)\n",
    "print('CatBoost F1_score', f1_score(target_test, predictions_ctb))\n",
    "print('CatBoost accuracy_score', accuracy_score(target_test, predictions_ctb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшую метрику F1 мы получили на модели LogReg; LightGBM, Catboost - показали метрику F1 меньшую, чем требуется. Что нового я узнала из нынешнего исследования? А вот что - для успешного выполнения работы потребовалось найти и занять на время ноут с опперативкой в 8Гб, процессором мощностью в 3,1 и подорожник. Потому что подорожник всегда поможет, это известно с детства."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
