{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Отток клиентов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из «Бета-Банка» стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.\n",
    "\n",
    "Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Нам предоставлены исторические данные о поведении клиентов и расторжении договоров с банком. \n",
    "\n",
    "Чтобы сдать проект успешно, нужно довести метрику до 0.59. \n",
    "\n",
    "Дополнительно нужно измерить *AUC-ROC* и сравнить её значение с *F1*-мерой.\n",
    "\n",
    "Источник данных: [https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling](https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Признаки датафрейма:\n",
    "RowNumber — индекс строки в данных\n",
    "CustomerId — уникальный идентификатор клиента\n",
    "Surname — фамилия\n",
    "CreditScore — кредитный рейтинг\n",
    "Geography — страна проживания\n",
    "Gender — пол\n",
    "Age — возраст\n",
    "Tenure — количество недвижимости у клиента\n",
    "Balance — баланс на счёте\n",
    "NumOfProducts — количество продуктов банка, используемых клиентом\n",
    "HasCrCard — наличие кредитной карты\n",
    "IsActiveMember — активность клиента\n",
    "EstimatedSalary — предполагаемая зарплата\n",
    "\n",
    "\n",
    "Целевой признак датафрейма:\n",
    "Exited — факт ухода клиента"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/datasets/Churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      "RowNumber          10000 non-null int64\n",
      "CustomerId         10000 non-null int64\n",
      "Surname            10000 non-null object\n",
      "CreditScore        10000 non-null int64\n",
      "Geography          10000 non-null object\n",
      "Gender             10000 non-null object\n",
      "Age                10000 non-null int64\n",
      "Tenure             9091 non-null float64\n",
      "Balance            10000 non-null float64\n",
      "NumOfProducts      10000 non-null int64\n",
      "HasCrCard          10000 non-null int64\n",
      "IsActiveMember     10000 non-null int64\n",
      "EstimatedSalary    10000 non-null float64\n",
      "Exited             10000 non-null int64\n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем все названия столбцов строчными, чтобы не было лишних промахов при наборе заглавного или строчного символа. Видим, что в есть ~ 1000 пропущенных значений в столбце о наличии недвижимости. Менять на нули не стоит - таким образом, исказится адекватность данных и их дальнейший анализ, а потом это всё повляет на доходность банка, которая будет измеряться сотнями тысяч ден. единиц: \"Assumptions are the mother of all mistakes\", как говорится в цензурном варианте цитаты. В данном случае, разумным будет решение удалить те строки, у которых значение Nan'ы. Да, будет потеряна ~ 1/10 часть информации, однако, данные будут корректными. Какие ещё манипуляции произведём с датой: уберём столбцы с фамилией,порядковым номером клинета и его ID - они могут повлиять на качество обучения моделей, плюс, наличие всех трёх показателей в данной ситуации можно считать избыточным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = map(str.lower, data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(subset = ['tenure'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.,  1.,  8.,  7.,  4.,  6.,  3., 10.,  5.,  9.,  0.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tenure'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['surname', 'rownumber', 'customerid'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приводим все флоаты в целочисленные значения, чтобы модели о них не спотыкались."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['balance'] = data['balance'].astype('int')\n",
    "data['tenure'] = data['tenure'].astype('int')\n",
    "data['estimatedsalary'] = data['estimatedsalary'].astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "creditscore         int64\n",
       "geography          object\n",
       "gender             object\n",
       "age                 int64\n",
       "tenure              int64\n",
       "balance             int64\n",
       "numofproducts       int64\n",
       "hascrcard           int64\n",
       "isactivemember      int64\n",
       "estimatedsalary     int64\n",
       "exited              int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Исследование задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проанализируем баланс классов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.796062\n",
       "1    0.203938\n",
       "Name: exited, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency = data['exited'].value_counts(normalize= True)\n",
    "frequency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "frequency.plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очевидно, что классы несбалансированы: пользователи уходят в 20% процентах случаев, или \"1\" больше \"0\" в 4 раза. Однако, продолжим изучать модели на этом шаге без учёта дисбаланса классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим пару функций, которая облегчит в дальнейшем объём и сэкономит время набора кода."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# возвращение целевого признака и признаков для обучения модели\n",
    "def tf(data, target_column='exited'):  \n",
    "    \n",
    "    target = data[target_column]\n",
    "    features = data.drop(target_column, axis=1)\n",
    "    return target, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# разделение даты на обуч., валидац. и тест. выборки в пропорции 6/2/2\n",
    "def split_data(features, target):\n",
    "    \n",
    "    features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "        features, target, test_size=0.4, random_state=12345\n",
    "    )\n",
    "\n",
    "    features_valid, features_test, target_valid, target_test = train_test_split(\n",
    "        features_valid, target_valid, test_size=0.5, random_state=12345\n",
    "    )\n",
    "    \n",
    "# масштабирование количественных признаков\n",
    "    scaler = StandardScaler()\n",
    "    numeric = ['creditscore', 'age', 'tenure', 'balance', 'numofproducts', 'estimatedsalary']\n",
    "    scaler.fit(features_train[numeric])\n",
    "    \n",
    "    features_train[numeric] = scaler.transform(features_train[numeric])\n",
    "    features_valid[numeric] = scaler.transform(features_valid[numeric])\n",
    "    features_test[numeric] = scaler.transform(features_test[numeric])\n",
    "    \n",
    "    return features_train, features_valid, features_test, target_train, target_valid, target_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# возвращение обученной модели\n",
    "def train_and_predict(data, model, log_prefix='', samplefunc=None, test=False):\n",
    "    \n",
    "    target, features = tf(data)\n",
    "    features_train, features_valid, features_test, target_train, target_valid, target_test = split_data(features, target)\n",
    "    \n",
    "    if samplefunc:\n",
    "        features_train, target_train = samplefunc(features_train, target_train)\n",
    "    \n",
    "    model.fit(features_train, target_train)\n",
    "    predicted_valid = model.predict(features_valid)\n",
    "    print(f'{log_prefix}F1-score на валидационной выборке: {f1_score(target_valid, predicted_valid)}')\n",
    "    \n",
    "    if test:\n",
    "        predictions_test = model.predict(features_test)\n",
    "        print(f'{log_prefix}F1-score на тестовой выборке: {f1_score(target_test, predicted_test)}')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим технику прямого кодирования, чтобы преобразовать категориальные признаки в численные для логистической регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ohe = pd.get_dummies(data, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score на валидационной выборке: 0.30400000000000005\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=12345, solver='liblinear', tol=0.0001,\n",
       "                   verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(solver='liblinear', random_state=12345)\n",
    "train_and_predict(data_ohe, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим технику порядкового кодирования для категориальных признаков в работе с моделями дерева решение и случайного леса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OrdinalEncoder()\n",
    "data_ordinal = pd.DataFrame(encoder.fit_transform(data), columns=data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дерево решений:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth 1:\tF1-score на валидационной выборке: 0.0\n",
      "max_depth 2:\tF1-score на валидационной выборке: 0.5304878048780488\n",
      "max_depth 3:\tF1-score на валидационной выборке: 0.3726708074534161\n",
      "max_depth 4:\tF1-score на валидационной выборке: 0.5414551607445008\n",
      "max_depth 5:\tF1-score на валидационной выборке: 0.5513698630136986\n",
      "max_depth 6:\tF1-score на валидационной выборке: 0.5106382978723404\n",
      "max_depth 7:\tF1-score на валидационной выборке: 0.5315161839863713\n",
      "max_depth 8:\tF1-score на валидационной выборке: 0.5085910652920962\n",
      "max_depth 9:\tF1-score на валидационной выборке: 0.515702479338843\n",
      "max_depth 10:\tF1-score на валидационной выборке: 0.5421133231240429\n",
      "max_depth 11:\tF1-score на валидационной выборке: 0.5164179104477611\n",
      "max_depth 12:\tF1-score на валидационной выборке: 0.5\n",
      "max_depth 13:\tF1-score на валидационной выборке: 0.4922206506364922\n",
      "max_depth 14:\tF1-score на валидационной выборке: 0.4798927613941019\n",
      "max_depth 15:\tF1-score на валидационной выборке: 0.4600811907983762\n",
      "max_depth 16:\tF1-score на валидационной выборке: 0.4746666666666667\n",
      "max_depth 17:\tF1-score на валидационной выборке: 0.45283018867924535\n",
      "max_depth 18:\tF1-score на валидационной выборке: 0.4562334217506631\n",
      "max_depth 19:\tF1-score на валидационной выборке: 0.4661458333333333\n",
      "max_depth 20:\tF1-score на валидационной выборке: 0.45144356955380577\n",
      "max_depth 21:\tF1-score на валидационной выборке: 0.45893089960886574\n",
      "max_depth 22:\tF1-score на валидационной выборке: 0.46923076923076923\n",
      "max_depth 23:\tF1-score на валидационной выборке: 0.4739583333333333\n",
      "max_depth 24:\tF1-score на валидационной выборке: 0.46923076923076923\n",
      "max_depth 25:\tF1-score на валидационной выборке: 0.46923076923076923\n",
      "max_depth 26:\tF1-score на валидационной выборке: 0.46923076923076923\n",
      "max_depth 27:\tF1-score на валидационной выборке: 0.46923076923076923\n",
      "max_depth 28:\tF1-score на валидационной выборке: 0.46923076923076923\n",
      "max_depth 29:\tF1-score на валидационной выборке: 0.46923076923076923\n",
      "max_depth 30:\tF1-score на валидационной выборке: 0.46923076923076923\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 31, 1):\n",
    "    model = DecisionTreeClassifier(max_depth=i, random_state=12345)\n",
    "    train_and_predict(data_ordinal, model, log_prefix=f'max_depth {i}:\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучший показатель F1 получился при глубине в 5 деревьев - 0.5513. Посмотрим, какой F1 получится с такой глубиной, когда примением модель случайного леса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Случайный лес:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 10:\tF1-score на валидационной выборке: 0.44047619047619047\n",
      "n_estimators = 20:\tF1-score на валидационной выборке: 0.4639376218323587\n",
      "n_estimators = 30:\tF1-score на валидационной выборке: 0.4799999999999999\n",
      "n_estimators = 40:\tF1-score на валидационной выборке: 0.5055762081784386\n",
      "n_estimators = 50:\tF1-score на валидационной выборке: 0.5111940298507462\n",
      "n_estimators = 60:\tF1-score на валидационной выборке: 0.5102420856610801\n",
      "n_estimators = 70:\tF1-score на валидационной выборке: 0.5257352941176471\n",
      "n_estimators = 80:\tF1-score на валидационной выборке: 0.5230202578268877\n",
      "n_estimators = 90:\tF1-score на валидационной выборке: 0.5257352941176471\n",
      "n_estimators = 100:\tF1-score на валидационной выборке: 0.5220588235294118\n",
      "n_estimators = 110:\tF1-score на валидационной выборке: 0.5247706422018349\n",
      "n_estimators = 120:\tF1-score на валидационной выборке: 0.5175600739371534\n",
      "n_estimators = 130:\tF1-score на валидационной выборке: 0.5175600739371534\n",
      "n_estimators = 140:\tF1-score на валидационной выборке: 0.5185185185185186\n",
      "n_estimators = 150:\tF1-score на валидационной выборке: 0.5230202578268877\n",
      "n_estimators = 160:\tF1-score на валидационной выборке: 0.5212569316081331\n",
      "n_estimators = 170:\tF1-score на валидационной выборке: 0.5193370165745855\n",
      "n_estimators = 180:\tF1-score на валидационной выборке: 0.526508226691042\n",
      "n_estimators = 190:\tF1-score на валидационной выборке: 0.5255474452554744\n",
      "n_estimators = 200:\tF1-score на валидационной выборке: 0.5228519195612431\n"
     ]
    }
   ],
   "source": [
    "for i in range(10, 201, 10):\n",
    "    model = RandomForestClassifier(n_estimators=i, max_depth=5, random_state=12345)\n",
    "    train_and_predict(data_ordinal, model, log_prefix=f'n_estimators = {i}:\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Глубина в 5 деревьев мне кажется недостаточной, точнее, с таким значением - надо посмотреть ещё и другие альтернативные варианты гиперпараметра, с помощью эвристики подкрутим глубину, стараясь получить максимальное значение F1. Покрутив значение \"за кадром\" вышла на глубину в 10 деревьев, при 30 в значении количества деревьев выходит max значение F1 ~ 0.58305. Подтверим это вычислениями:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 10:\tF1-score на валидационной выборке: 0.5690235690235691\n",
      "n_estimators = 20:\tF1-score на валидационной выборке: 0.5724020442930153\n",
      "n_estimators = 30:\tF1-score на валидационной выборке: 0.5830508474576271\n",
      "n_estimators = 40:\tF1-score на валидационной выборке: 0.5733788395904437\n",
      "n_estimators = 50:\tF1-score на валидационной выборке: 0.5660377358490567\n",
      "n_estimators = 60:\tF1-score на валидационной выборке: 0.5655172413793104\n",
      "n_estimators = 70:\tF1-score на валидационной выборке: 0.5660377358490567\n",
      "n_estimators = 80:\tF1-score на валидационной выборке: 0.5660377358490567\n",
      "n_estimators = 90:\tF1-score на валидационной выборке: 0.5565217391304348\n",
      "n_estimators = 100:\tF1-score на валидационной выборке: 0.5640138408304498\n",
      "n_estimators = 110:\tF1-score на валидационной выборке: 0.5555555555555556\n",
      "n_estimators = 120:\tF1-score на валидационной выборке: 0.5555555555555556\n",
      "n_estimators = 130:\tF1-score на валидационной выборке: 0.5580589254766032\n",
      "n_estimators = 140:\tF1-score на валидационной выборке: 0.5611015490533563\n",
      "n_estimators = 150:\tF1-score на валидационной выборке: 0.5655172413793104\n",
      "n_estimators = 160:\tF1-score на валидационной выборке: 0.563573883161512\n",
      "n_estimators = 170:\tF1-score на валидационной выборке: 0.5620689655172414\n",
      "n_estimators = 180:\tF1-score на валидационной выборке: 0.5620689655172414\n",
      "n_estimators = 190:\tF1-score на валидационной выборке: 0.5679862306368331\n",
      "n_estimators = 200:\tF1-score на валидационной выборке: 0.5645438898450946\n"
     ]
    }
   ],
   "source": [
    "for i in range(10, 201, 10):\n",
    "    model = RandomForestClassifier(n_estimators=i, max_depth=10, random_state=12345)\n",
    "    train_and_predict(data_ordinal, model, log_prefix=f'n_estimators = {i}:\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Борьба с дисбалансом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сбалансируем классы с помощью аргумента class_weight, начнём смотреть результаты на регрессии:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score на валидационной выборке: 0.509731232622799\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=12345, solver='liblinear', tol=0.0001,\n",
       "                   verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(class_weight='balanced', solver='liblinear', random_state=12345)\n",
    "train_and_predict(data_ohe, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значение F1 увеличилось с ~0.304 до ~0.509."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дерево решений:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth 1:\tF1-score на валидационной выборке: 0.5065856129685917\n",
      "max_depth 2:\tF1-score на валидационной выборке: 0.5297619047619048\n",
      "max_depth 3:\tF1-score на валидационной выборке: 0.548936170212766\n",
      "max_depth 4:\tF1-score на валидационной выборке: 0.5045492142266335\n",
      "max_depth 5:\tF1-score на валидационной выборке: 0.5758928571428572\n",
      "max_depth 6:\tF1-score на валидационной выборке: 0.574370709382151\n",
      "max_depth 7:\tF1-score на валидационной выборке: 0.5118577075098815\n",
      "max_depth 8:\tF1-score на валидационной выборке: 0.5362637362637362\n",
      "max_depth 9:\tF1-score на валидационной выборке: 0.4965104685942173\n",
      "max_depth 10:\tF1-score на валидационной выборке: 0.4988962472406181\n",
      "max_depth 11:\tF1-score на валидационной выборке: 0.49002217294900213\n",
      "max_depth 12:\tF1-score на валидационной выборке: 0.4889406286379511\n",
      "max_depth 13:\tF1-score на валидационной выборке: 0.4720194647201946\n",
      "max_depth 14:\tF1-score на валидационной выборке: 0.48152866242038217\n",
      "max_depth 15:\tF1-score на валидационной выборке: 0.47306176084099866\n",
      "max_depth 16:\tF1-score на валидационной выборке: 0.4708994708994709\n",
      "max_depth 17:\tF1-score на валидационной выборке: 0.46194926568758343\n",
      "max_depth 18:\tF1-score на валидационной выборке: 0.472630173564753\n",
      "max_depth 19:\tF1-score на валидационной выборке: 0.4791386271870794\n",
      "max_depth 20:\tF1-score на валидационной выборке: 0.4777327935222672\n",
      "max_depth 21:\tF1-score на валидационной выборке: 0.47967479674796754\n",
      "max_depth 22:\tF1-score на валидационной выборке: 0.480325644504749\n",
      "max_depth 23:\tF1-score на валидационной выборке: 0.4756756756756757\n",
      "max_depth 24:\tF1-score на валидационной выборке: 0.4756756756756757\n",
      "max_depth 25:\tF1-score на валидационной выборке: 0.4756756756756757\n",
      "max_depth 26:\tF1-score на валидационной выборке: 0.4756756756756757\n",
      "max_depth 27:\tF1-score на валидационной выборке: 0.4756756756756757\n",
      "max_depth 28:\tF1-score на валидационной выборке: 0.4756756756756757\n",
      "max_depth 29:\tF1-score на валидационной выборке: 0.4756756756756757\n",
      "max_depth 30:\tF1-score на валидационной выборке: 0.4756756756756757\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 31, 1):\n",
    "    model = DecisionTreeClassifier(class_weight='balanced', max_depth=i, random_state=12345)\n",
    "    train_and_predict(data_ordinal, model, log_prefix=f'max_depth {i}:\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью балансировки на шиномонтажке (зачёркнуто) 0.5513 получилось поднять до 0.5758 при 5 глубине в 5 единици деревьем. В модели случайного леса будем так же настраивать глубину деревьев с помощью эвристики, а пока стартанём с показателя в 5 деревьев."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель случайного леса:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 10:\tF1-score на валидационной выборке: 0.5825242718446602\n",
      "n_estimators = 20:\tF1-score на валидационной выборке: 0.5925925925925927\n",
      "n_estimators = 30:\tF1-score на валидационной выборке: 0.5995670995670995\n",
      "n_estimators = 40:\tF1-score на валидационной выборке: 0.6067907995618839\n",
      "n_estimators = 50:\tF1-score на валидационной выборке: 0.5961123110151187\n",
      "n_estimators = 60:\tF1-score на валидационной выборке: 0.5911542610571737\n",
      "n_estimators = 70:\tF1-score на валидационной выборке: 0.593311758360302\n",
      "n_estimators = 80:\tF1-score на валидационной выборке: 0.5941872981700754\n",
      "n_estimators = 90:\tF1-score на валидационной выборке: 0.5976267529665589\n",
      "n_estimators = 100:\tF1-score на валидационной выборке: 0.5894962486602358\n",
      "n_estimators = 110:\tF1-score на валидационной выборке: 0.5913978494623655\n",
      "n_estimators = 120:\tF1-score на валидационной выборке: 0.5921192758253462\n",
      "n_estimators = 130:\tF1-score на валидационной выборке: 0.592274678111588\n",
      "n_estimators = 140:\tF1-score на валидационной выборке: 0.5959271168274384\n",
      "n_estimators = 150:\tF1-score на валидационной выборке: 0.5931477516059958\n",
      "n_estimators = 160:\tF1-score на валидационной выборке: 0.5944206008583691\n",
      "n_estimators = 170:\tF1-score на валидационной выборке: 0.5954692556634305\n",
      "n_estimators = 180:\tF1-score на валидационной выборке: 0.5956989247311828\n",
      "n_estimators = 190:\tF1-score на валидационной выборке: 0.5969827586206896\n",
      "n_estimators = 200:\tF1-score на валидационной выборке: 0.5929108485499464\n"
     ]
    }
   ],
   "source": [
    "for i in range(10, 201, 10):\n",
    "    model = RandomForestClassifier(class_weight='balanced', n_estimators=i, max_depth=5, random_state=12345)\n",
    "    train_and_predict(data_ordinal, model, log_prefix=f'n_estimators = {i}:\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Покрутив снова \"за кадром\" глубину получили максимальное значение F1 в 0.6390 при значении в 11 единиц глубины деревьев, а количестве - в 30. Подтвердим сказанное:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 10:\tF1-score на валидационной выборке: 0.5956873315363881\n",
      "n_estimators = 20:\tF1-score на валидационной выборке: 0.6282578875171468\n",
      "n_estimators = 30:\tF1-score на валидационной выборке: 0.6390041493775934\n",
      "n_estimators = 40:\tF1-score на валидационной выборке: 0.6358543417366946\n",
      "n_estimators = 50:\tF1-score на валидационной выборке: 0.6362339514978601\n",
      "n_estimators = 60:\tF1-score на валидационной выборке: 0.6311360448807855\n",
      "n_estimators = 70:\tF1-score на валидационной выборке: 0.6302521008403361\n",
      "n_estimators = 80:\tF1-score на валидационной выборке: 0.6283309957924264\n",
      "n_estimators = 90:\tF1-score на валидационной выборке: 0.6276150627615062\n",
      "n_estimators = 100:\tF1-score на валидационной выборке: 0.6203966005665723\n",
      "n_estimators = 110:\tF1-score на валидационной выборке: 0.6182336182336182\n",
      "n_estimators = 120:\tF1-score на валидационной выборке: 0.6201991465149359\n",
      "n_estimators = 130:\tF1-score на валидационной выборке: 0.6193181818181819\n",
      "n_estimators = 140:\tF1-score на валидационной выборке: 0.6216596343178621\n",
      "n_estimators = 150:\tF1-score на валидационной выборке: 0.6218487394957982\n",
      "n_estimators = 160:\tF1-score на валидационной выборке: 0.6293706293706294\n",
      "n_estimators = 170:\tF1-score на валидационной выборке: 0.6242937853107344\n",
      "n_estimators = 180:\tF1-score на валидационной выборке: 0.628005657708628\n",
      "n_estimators = 190:\tF1-score на валидационной выборке: 0.6260623229461756\n",
      "n_estimators = 200:\tF1-score на валидационной выборке: 0.6264044943820225\n"
     ]
    }
   ],
   "source": [
    "for i in range(10, 201, 10):\n",
    "    model = RandomForestClassifier(class_weight='balanced', n_estimators=i, max_depth=11, random_state=12345)\n",
    "    train_and_predict(data_ordinal, model, log_prefix=f'n_estimators = {i}:\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 200:\tF1-score на валидационной выборке: 0.6223277909738718\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight='balanced',\n",
       "               colsample_bytree=1.0, importance_type='split', learning_rate=0.1,\n",
       "               max_depth=-1, min_child_samples=20, min_child_weight=0.001,\n",
       "               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,\n",
       "               objective=None, random_state=12345, reg_alpha=0.0,\n",
       "               reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "               subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LGBMClassifier(class_weight='balanced', random_state=12345)\n",
    "train_and_predict(data_ordinal, model, log_prefix=f'n_estimators = {i}:\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучший показатель по F1 показала модель случайного леса с class_weight='balanced', её и будем тестировать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим технику уменьшения выборки - downsampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(features, target, fraction = 0.2):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_downsampled = pd.concat(\n",
    "        [features_zeros.sample(frac=fraction, random_state=12345)] + [features_ones]\n",
    "    )\n",
    "    target_downsampled = pd.concat(\n",
    "        [target_zeros.sample(frac=fraction, random_state=12345)] + [target_ones]\n",
    "    )\n",
    "    \n",
    "    return features_downsampled, target_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score на валидационной выборке: 0.48878205128205127\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=12345, solver='liblinear', tol=0.0001,\n",
       "                   verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(solver='liblinear', random_state=12345)\n",
    "train_and_predict(data_ohe, model, samplefunc=downsample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значение F1 упало: 0.509 vs 0.488"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth 1:\tF1-score на валидационной выборке: 0.49555950266429843\n",
      "max_depth 2:\tF1-score на валидационной выборке: 0.5100788781770377\n",
      "max_depth 3:\tF1-score на валидационной выборке: 0.5644599303135889\n",
      "max_depth 4:\tF1-score на валидационной выборке: 0.5242399342645849\n",
      "max_depth 5:\tF1-score на валидационной выборке: 0.5529197080291971\n",
      "max_depth 6:\tF1-score на валидационной выборке: 0.533003300330033\n",
      "max_depth 7:\tF1-score на валидационной выборке: 0.5178268251273345\n",
      "max_depth 8:\tF1-score на валидационной выборке: 0.5238938053097345\n",
      "max_depth 9:\tF1-score на валидационной выборке: 0.5221238938053097\n",
      "max_depth 10:\tF1-score на валидационной выборке: 0.5340699815837937\n",
      "max_depth 11:\tF1-score на валидационной выборке: 0.5113438045375218\n",
      "max_depth 12:\tF1-score на валидационной выборке: 0.5057880676758681\n",
      "max_depth 13:\tF1-score на валидационной выборке: 0.5044563279857398\n",
      "max_depth 14:\tF1-score на валидационной выборке: 0.497391304347826\n",
      "max_depth 15:\tF1-score на валидационной выборке: 0.49426301853486315\n",
      "max_depth 16:\tF1-score на валидационной выборке: 0.4861111111111111\n",
      "max_depth 17:\tF1-score на валидационной выборке: 0.4921739130434782\n",
      "max_depth 18:\tF1-score на валидационной выборке: 0.49043478260869566\n",
      "max_depth 19:\tF1-score на валидационной выборке: 0.49043478260869566\n",
      "max_depth 20:\tF1-score на валидационной выборке: 0.49043478260869566\n",
      "max_depth 21:\tF1-score на валидационной выборке: 0.49043478260869566\n",
      "max_depth 22:\tF1-score на валидационной выборке: 0.49043478260869566\n",
      "max_depth 23:\tF1-score на валидационной выборке: 0.49043478260869566\n",
      "max_depth 24:\tF1-score на валидационной выборке: 0.49043478260869566\n",
      "max_depth 25:\tF1-score на валидационной выборке: 0.49043478260869566\n",
      "max_depth 26:\tF1-score на валидационной выборке: 0.49043478260869566\n",
      "max_depth 27:\tF1-score на валидационной выборке: 0.49043478260869566\n",
      "max_depth 28:\tF1-score на валидационной выборке: 0.49043478260869566\n",
      "max_depth 29:\tF1-score на валидационной выборке: 0.49043478260869566\n",
      "max_depth 30:\tF1-score на валидационной выборке: 0.49043478260869566\n"
     ]
    }
   ],
   "source": [
    "for max_depth in range(1, 31, 1):\n",
    "    model = DecisionTreeClassifier(max_depth=max_depth, random_state=12345)\n",
    "    train_and_predict(data_ordinal, model, samplefunc=downsample, log_prefix=f'max_depth {max_depth}:\\t')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также падение: 0.5758 vs 0.5644"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 10:\tF1-score на валидационной выборке: 0.5424354243542435\n",
      "n_estimators = 20:\tF1-score на валидационной выборке: 0.5514184397163121\n",
      "n_estimators = 30:\tF1-score на валидационной выборке: 0.544157002676182\n",
      "n_estimators = 40:\tF1-score на валидационной выборке: 0.549469964664311\n",
      "n_estimators = 50:\tF1-score на валидационной выборке: 0.5517241379310345\n",
      "n_estimators = 60:\tF1-score на валидационной выборке: 0.5513608428446005\n",
      "n_estimators = 70:\tF1-score на валидационной выборке: 0.5640569395017794\n",
      "n_estimators = 80:\tF1-score на валидационной выборке: 0.559576345984113\n",
      "n_estimators = 90:\tF1-score на валидационной выборке: 0.5530035335689045\n",
      "n_estimators = 100:\tF1-score на валидационной выборке: 0.5601404741000878\n",
      "n_estimators = 110:\tF1-score на валидационной выборке: 0.5638766519823789\n",
      "n_estimators = 120:\tF1-score на валидационной выборке: 0.5628318584070797\n",
      "n_estimators = 130:\tF1-score на валидационной выборке: 0.5646017699115045\n",
      "n_estimators = 140:\tF1-score на валидационной выборке: 0.5611257695690414\n",
      "n_estimators = 150:\tF1-score на валидационной выборке: 0.5609114811568799\n",
      "n_estimators = 160:\tF1-score на валидационной выборке: 0.5621716287215411\n",
      "n_estimators = 170:\tF1-score на валидационной выборке: 0.5569176882661997\n",
      "n_estimators = 180:\tF1-score на валидационной выборке: 0.5598591549295774\n",
      "n_estimators = 190:\tF1-score на валидационной выборке: 0.5568281938325991\n",
      "n_estimators = 200:\tF1-score на валидационной выборке: 0.5536028119507908\n"
     ]
    }
   ],
   "source": [
    "for estim in range(10, 201, 10):\n",
    "    model = RandomForestClassifier(n_estimators=estim, max_depth=19, random_state=12345)\n",
    "    train_and_predict(data_ordinal, model, samplefunc=downsample, log_prefix=f'n_estimators = {estim}:\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я снова покрутила вручную глубину деревьев, подняв её, но смогла добиться только значения ~ 0.5759. Причем, значение не подымалось и не опускалось драматически, даже если ранжирование настройки глубины были 19, 23, 27, 35 соответственно. Как будто значение вышло на плато."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь займёмся увеличением выборки: сделаем объекты редкого класса не такими редкими и переобучим модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(features, target, repeat=4):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "    \n",
    "    features_upsampled, target_upsampled = shuffle(\n",
    "        features_upsampled, target_upsampled, random_state=12345)\n",
    "    \n",
    "    return features_upsampled, target_upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score на валидационной выборке: 0.5085972850678734\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=12345, solver='liblinear', tol=0.0001,\n",
       "                   verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(solver='liblinear', random_state=12345)\n",
    "train_and_predict(data_ohe, model, samplefunc=upsample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 упал с 0.509 до 0.415, спойлер - там дальше вообще всё упадёт (\"Наташ, вставай, мы там всё уронили\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth 1:\tF1-score на валидационной выборке: 0.5065856129685917\n",
      "max_depth 2:\tF1-score на валидационной выборке: 0.5297619047619048\n",
      "max_depth 3:\tF1-score на валидационной выборке: 0.548936170212766\n",
      "max_depth 4:\tF1-score на валидационной выборке: 0.5045492142266335\n",
      "max_depth 5:\tF1-score на валидационной выборке: 0.5758928571428572\n",
      "max_depth 6:\tF1-score на валидационной выборке: 0.5562248995983935\n",
      "max_depth 7:\tF1-score на валидационной выборке: 0.5118577075098815\n",
      "max_depth 8:\tF1-score на валидационной выборке: 0.5314109165808445\n",
      "max_depth 9:\tF1-score на валидационной выборке: 0.4945164506480558\n",
      "max_depth 10:\tF1-score на валидационной выборке: 0.5083240843507214\n",
      "max_depth 11:\tF1-score на валидационной выборке: 0.48903508771929827\n",
      "max_depth 12:\tF1-score на валидационной выборке: 0.4821222606689735\n",
      "max_depth 13:\tF1-score на валидационной выборке: 0.4690157958687728\n",
      "max_depth 14:\tF1-score на валидационной выборке: 0.48311688311688317\n",
      "max_depth 15:\tF1-score на валидационной выборке: 0.48500651890482405\n",
      "max_depth 16:\tF1-score на валидационной выборке: 0.4646194926568759\n",
      "max_depth 17:\tF1-score на валидационной выборке: 0.4722955145118733\n",
      "max_depth 18:\tF1-score на валидационной выборке: 0.4734042553191489\n",
      "max_depth 19:\tF1-score на валидационной выборке: 0.4497991967871486\n",
      "max_depth 20:\tF1-score на валидационной выборке: 0.45100671140939597\n",
      "max_depth 21:\tF1-score на валидационной выборке: 0.45272969374167776\n",
      "max_depth 22:\tF1-score на валидационной выборке: 0.45308310991957107\n",
      "max_depth 23:\tF1-score на валидационной выборке: 0.45247657295850063\n",
      "max_depth 24:\tF1-score на валидационной выборке: 0.45247657295850063\n",
      "max_depth 25:\tF1-score на валидационной выборке: 0.45247657295850063\n",
      "max_depth 26:\tF1-score на валидационной выборке: 0.45247657295850063\n",
      "max_depth 27:\tF1-score на валидационной выборке: 0.45247657295850063\n",
      "max_depth 28:\tF1-score на валидационной выборке: 0.45247657295850063\n",
      "max_depth 29:\tF1-score на валидационной выборке: 0.45247657295850063\n",
      "max_depth 30:\tF1-score на валидационной выборке: 0.45247657295850063\n"
     ]
    }
   ],
   "source": [
    "for max_depth in range(1, 31, 1):\n",
    "    model = DecisionTreeClassifier(max_depth=max_depth, random_state=12345)\n",
    "    train_and_predict(data_ordinal, model, samplefunc=upsample, log_prefix=f'max_depth {max_depth}:\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 10:\tF1-score на валидационной выборке: 0.5748987854251013\n",
      "n_estimators = 20:\tF1-score на валидационной выборке: 0.598079561042524\n",
      "n_estimators = 30:\tF1-score на валидационной выборке: 0.6030855539971949\n",
      "n_estimators = 40:\tF1-score на валидационной выборке: 0.6125874125874127\n",
      "n_estimators = 50:\tF1-score на валидационной выборке: 0.6147426981919333\n",
      "n_estimators = 60:\tF1-score на валидационной выборке: 0.6213592233009709\n",
      "n_estimators = 70:\tF1-score на валидационной выборке: 0.6181818181818182\n",
      "n_estimators = 80:\tF1-score на валидационной выборке: 0.6179775280898876\n",
      "n_estimators = 90:\tF1-score на валидационной выборке: 0.6227208976157081\n",
      "n_estimators = 100:\tF1-score на валидационной выборке: 0.620979020979021\n",
      "n_estimators = 110:\tF1-score на валидационной выборке: 0.6246498599439777\n",
      "n_estimators = 120:\tF1-score на валидационной выборке: 0.6143057503506312\n",
      "n_estimators = 130:\tF1-score на валидационной выборке: 0.6188466947960618\n",
      "n_estimators = 140:\tF1-score на валидационной выборке: 0.6197183098591549\n"
     ]
    }
   ],
   "source": [
    "for estim in range(10, 150, 10):\n",
    "    model = RandomForestClassifier(n_estimators=estim, max_depth=14, random_state=12345)\n",
    "    train_and_predict(data_ordinal, model, samplefunc=upsample, log_prefix=f'n_estimators = {estim}:\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В случайном лесе я снова вручную подбирала глубину, и лучший показатель F1 (0.6355 vs 0.6390) зафиксирован на глубине в 14 деревьев. Во время консультации с наставником, ребята-студенты упоминали, что у них получилось докрутить max F1 с помощью апсамплинга. Понятное дело, что без обзора их кода - сложно объяснить, почему у них получилось, а в моём случае - балансировка классов показала себя самой эффективной метрикой. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Тестирование модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подбор гиперпараметров для тестирования модели я производила вручную, несмотря на то, что у меня были показатели в 11 глубины и 30 штук деревьев (F1 ~ 0.59). Покрутив количество и глубину, пришла к тому, что количество деревьев в 150 даёт самый высокий результат F1 в ~ 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid: 0.6218487394957982\n",
      "test: 0.6000000000000001\n"
     ]
    }
   ],
   "source": [
    "target, features = tf(data_ordinal)\n",
    "features_train, features_valid, features_test, target_train, target_valid, target_test = split_data(features, target)\n",
    "\n",
    "model = RandomForestClassifier(class_weight='balanced', n_estimators=150, max_depth=11, random_state=12345)\n",
    "model.fit(features_train, target_train)\n",
    "\n",
    "predicted_valid = model.predict(features_valid)\n",
    "print('valid:', f1_score(target_valid, predicted_valid))\n",
    "\n",
    "predicted_test = model.predict(features_test)\n",
    "print('test:', f1_score(target_test, predicted_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid: 0.6211180124223603\n",
      "test: 0.5827814569536425\n"
     ]
    }
   ],
   "source": [
    "target, features = tf(data_ordinal)\n",
    "features_train, features_valid, features_test, target_train, target_valid, target_test = split_data(features, target)\n",
    "\n",
    "model = LGBMClassifier(class_weight='balanced', n_estimators=200, max_depth=11, random_state=12345)\n",
    "model.fit(features_train, target_train)\n",
    "\n",
    "predicted_valid = model.predict(features_valid)\n",
    "print('valid:', f1_score(target_valid, predicted_valid))\n",
    "\n",
    "predicted_test = model.predict(features_test)\n",
    "print('test:', f1_score(target_test, predicted_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8510336728288821"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "roc_auc_score(target_valid, probabilities_one_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрика F1-мера равна 0.6, высота взята.\n",
    "Метрика AUC-ROC равна 0.86. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid: 0.8639129042587256\n",
      "test: 0.5919540229885057\n"
     ]
    }
   ],
   "source": [
    "target, features = tf(data_ordinal)\n",
    "features_train, features_valid, features_test, target_train, target_valid, target_test = split_data(features, target)\n",
    "features_train_val = pd.concat([features_train] + [features_valid])\n",
    "target_train_val = pd.concat([target_train] + [target_valid])\n",
    "\n",
    "features_train_valid = pd.concat([features_train] + [features_valid])\n",
    "target_train_valid = pd.concat([target_train] + [target_valid])\n",
    "\n",
    "model = RandomForestClassifier(class_weight='balanced', n_estimators=150, max_depth=11, random_state=12345)\n",
    "model.fit(features_train_valid, target_train_valid)\n",
    "\n",
    "predicted_valid = model.predict(features_train_valid)\n",
    "print('valid:', f1_score(target_train_valid, predicted_valid)) \n",
    "\n",
    "predicted_test = model.predict(features_test)\n",
    "print('test:', f1_score(target_test, predicted_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
